{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1sNjvZMqhEsK"
      },
      "outputs": [],
      "source": [
        "import keras # Import the Keras library\n",
        "from keras.datasets import mnist # Load the MNIST dataset\n",
        "from keras.models import Sequential # Initialize a sequential model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset from Keras\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Print the shape of the training and test data\n",
        "print(x_train.shape, y_train.shape)\n",
        "\n",
        "# Reshape the training and test data to 4 dimensions\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Convert the labels to categorical format\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "# Convert the pixel values to floats between 0 and 1\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalize the pixel values by dividing them by 255\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Define the batch size and number of classes\n",
        "batch_size = 60\n",
        "num_classes = 10\n",
        "\n",
        "# Define the number of epochs to train the model for\n",
        "epochs = 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNRENvzHhL1j",
        "outputId": "9e13589f-c086-4585-e22e-f0a09d123afb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    CNN model for MNIST digit classification.\n",
        "    Args:\n",
        "       optimizer: the optimizer to use for training the model\n",
        "    Returns:\n",
        "       a compiled Keras model.\n",
        "'''\n",
        "\n",
        "def build_model(optimizer):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "fttWhTlChYbs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers=['Adagrad','Adam','SGD']\n",
        "histories ={opt:build_model(opt).fit(x_train,y_train,batch_size=batch_size,\n",
        "epochs=epochs,verbose=1,validation_data=(x_test,y_test)) for opt in optimizers}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SipFmFVEhqhw",
        "outputId": "dabbebc9-6623-4d74-80ad-fa078e3bfff4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 33s 33ms/step - loss: 1.6074 - accuracy: 0.5358 - val_loss: 0.7917 - val_accuracy: 0.8468\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.8021 - accuracy: 0.7682 - val_loss: 0.4810 - val_accuracy: 0.8849\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.6186 - accuracy: 0.8186 - val_loss: 0.3944 - val_accuracy: 0.8984\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.5427 - accuracy: 0.8386 - val_loss: 0.3514 - val_accuracy: 0.9085\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.4978 - accuracy: 0.8517 - val_loss: 0.3254 - val_accuracy: 0.9133\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.4647 - accuracy: 0.8620 - val_loss: 0.3071 - val_accuracy: 0.9165\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.4399 - accuracy: 0.8692 - val_loss: 0.2905 - val_accuracy: 0.9195\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.4251 - accuracy: 0.8741 - val_loss: 0.2792 - val_accuracy: 0.9213\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.4105 - accuracy: 0.8776 - val_loss: 0.2685 - val_accuracy: 0.9232\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.3964 - accuracy: 0.8818 - val_loss: 0.2599 - val_accuracy: 0.9257\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 31s 30ms/step - loss: 0.2900 - accuracy: 0.9123 - val_loss: 0.0718 - val_accuracy: 0.9764\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.1131 - accuracy: 0.9661 - val_loss: 0.0535 - val_accuracy: 0.9823\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0900 - accuracy: 0.9725 - val_loss: 0.0470 - val_accuracy: 0.9840\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0751 - accuracy: 0.9774 - val_loss: 0.0421 - val_accuracy: 0.9846\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0628 - accuracy: 0.9806 - val_loss: 0.0371 - val_accuracy: 0.9869\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 32s 32ms/step - loss: 0.0568 - accuracy: 0.9821 - val_loss: 0.0410 - val_accuracy: 0.9871\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0511 - accuracy: 0.9839 - val_loss: 0.0355 - val_accuracy: 0.9875\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 30s 30ms/step - loss: 0.0471 - accuracy: 0.9851 - val_loss: 0.0426 - val_accuracy: 0.9863\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0444 - accuracy: 0.9855 - val_loss: 0.0360 - val_accuracy: 0.9892\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 31s 31ms/step - loss: 0.0393 - accuracy: 0.9872 - val_loss: 0.0367 - val_accuracy: 0.9884\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.8736 - accuracy: 0.7306 - val_loss: 0.3182 - val_accuracy: 0.9085\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.4281 - accuracy: 0.8700 - val_loss: 0.2388 - val_accuracy: 0.9325\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.3541 - accuracy: 0.8924 - val_loss: 0.1996 - val_accuracy: 0.9444\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.3119 - accuracy: 0.9057 - val_loss: 0.1767 - val_accuracy: 0.9508\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2882 - accuracy: 0.9137 - val_loss: 0.1581 - val_accuracy: 0.9545\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2688 - accuracy: 0.9203 - val_loss: 0.1480 - val_accuracy: 0.9550\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2545 - accuracy: 0.9248 - val_loss: 0.1384 - val_accuracy: 0.9589\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 29s 29ms/step - loss: 0.2402 - accuracy: 0.9272 - val_loss: 0.1286 - val_accuracy: 0.9624\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2318 - accuracy: 0.9304 - val_loss: 0.1250 - val_accuracy: 0.9638\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 28s 28ms/step - loss: 0.2184 - accuracy: 0.9340 - val_loss: 0.1192 - val_accuracy: 0.9647\n"
          ]
        }
      ]
    }
  ]
}